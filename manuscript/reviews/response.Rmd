---
title: "Response to Comments"
output:
  pdf_document: default
  html_notebook: default
  html_document: default
  word_document: default
---

## Reviewer 1


#### Comment
Bug: A graph is produced as expected if the code below is cut-and-pasted at the command line .  However, if the code is put into a file (say `foo.R`) and `source("foo.R")` is executed at the command line, no graph is produced.  (But note that if `plot=TRUE` is added to the call to `partial()`, then a plot is produced as expected.)
```{r, eval=FALSE}
library(randomForest)
data(airquality)
ozone.rf <- randomForest(Ozone ~ ., data=airquality, na.action=na.omit)
library(pdp)
pd <- partial(ozone.rf, pred.var="Temp")
plotPartial(pd)
```

#### Response
This is simply a side effect of using `lattice` to produce the plots. If sourcing a script, then the plot needs to be explicitly printed (e.g., `print(plotPartial(pd))`).


#### Comment
I couldn't get `partial` to work with `gbm` (version 2.1.1) models (although I didn't try very hard).  Perhaps this is because the `gbm` maintainer changed the `gbm` interface in a non-backcompatible way.  The following (where `gbm.mod` is a model built using the gbm package)
```{r, eval=FALSE}
partial(gbm.mod, pred.var="age")
```
gives
```{r, eval=FALSE}
Error in paste("Using", n.trees, "trees...\n") :
argument "n.trees" is missing, with no default
```
I also tried
```{r, eval=FALSE}
partial(gbm.mod, pred.var="age", n.trees=100)
```
but that gives
```{r, eval=FALSE}
Error in .fun(piece, ...) : unused argument (n.trees = 100)
```

#### Response
This been fixed in `pdp` (version 0.3.0), but requires the user to supply `n.trees` in the call to `partial`. So, `partial(gbm.mod, pred.var="age", n.trees=100)` should work now. The test suite is being expanded, as suggested in a later comment, to help catch more errors like this.


#### Comment
Standard partial matching isn't implemented (e.g., `partial(..., type="r")`).

#### Response
Partial matching is now implemented, but only for the `type` argument.


#### Comment
The following code incorrectly gives an error message
```
"Error in names(pd_df) <- c(pred.var, "y") :
  'names' attribute [2] must be the same length as the vector [1]"
```
It seems to work ok if you change the variable names.
```{r, eval=FALSE}
library(pdp)
data <- data.frame(V1=1:10, V2=1:10)
mod <- lm(V2~V1, data=data)
partial(mod, pred.var="V1", plot=TRUE) # error
```

#### Response
This has been fixed in `pdp` (version 0.3.0). This was simply a side effect of `partial`'s internal use of `plyr::adply` which uses default variable names (e.g., `V1`, `V2`, etc.). This caused the column `V1` in the output data frame to be overwritten, producing the error. 
```{r, eval=TRUE}
library(pdp)
data <- data.frame(V1=1:10, V2=1:10)
mod <- lm(V2~V1, data=data)
partial(mod, pred.var="V1") # no more error
```


#### Comment
I think you should mention in the documentation something about the assumptions you make about accessing the model data. The following (somewhat contrived) example fails with
`"Error in train[[x]] : subscript out of bounds":`
```{r, eval=FALSE}
data(trees)
foo <- function(data)
{
    lm(Volume~., data=data)
}
mod <- foo(trees)
library(pdp)
partial(mod, pred.var="Girth", plot=TRUE) # fails
```
and the following silently gives misleading results:

```{r, eval=FALSE}
library(pdp)
data(trees)
mod <- lm(Volume~., data=trees)
partial(mod, pred.var="Girth", plot=TRUE) # ok
trees <- trees[1:2,]
partial(mod, pred.var="Girth", plot=TRUE) # wrong xlim
```
I'm not necessarily saying that you need to resolve the above two
issues, but at least mention in the documentation that this kind of
thing can happen, and how to avoid it (basically call partial in the
same environment used to build the model, and don't change any of the
data used to build the model).


#### Comment
The following code gives an obscure error message:
```
"Error in seq.default(from = min(train[[x]], na.rm = TRUE),
   to = max(train[[x]],  :
  'from' cannot be NA, NaN or infinite"
```
Some better handholding for the user may be helpful here.
```{r, eval=FALSE}
library(pdp)
data(trees)
mod <- lm(Volume~., data=trees)
partial(mod, pred.var="nosuchvariable", plot=TRUE) # obscure err msg
```

#### Response
This has been fixed in `pdp` (version 0.3.0) by adding an informative error message listing which variables are the cause of the issue.
```{r, eval=FALSE}
library(pdp)
data(trees)
mod <- lm(Volume~., data=trees)
partial(mod, pred.var=c("Girth", "foo", "bar"), plot=TRUE)
```
```
Error in partial.default(mod, pred.var = "nosuchvariable", plot = TRUE) : 
  nosuchvariable not found in the training data.
```


#### Comment
On page 2 of the paper it says "The columns of the data frame are labeled in the same order as the features supplied to `pred.var`, and the last column is always labeled `y`". What happens if `y` is one of the predictors?

#### Response
The last column is labeled `y` for consistency with `gbm` and `randomForest` behavior. Only `gbm` does not fail in this case.


#### Comment
Hastie et al. in the book cited in the paper say "Although such a collection [of partial dependence plots] can seldom provide a comprehensive depiction of the approximation, it can often produce helpful clues".  Therefore in in the abstract for the paper, to avoid overselling consider changing "relationship between the outcome and predictors of interest can be easily understood" to "relationship between the outcome and predictors of interest can be more easily understood".

#### Response
Fixed.


#### Comment
On page 3 in the PDF of the paper, add a newline to the error message in the paper:
```
Error: The training data could not be extracted from object. Please
supply the raw training data using the ...
```

#### Response
Fixed.


#### Comment
Is there any reason the package is called `pdp` but the main function is called `partial`?  Consider giving the function the same name as the package, so e.g the following works (to help the user get started)
```{r, eval=FALSE}
library(pdp)
?pdp # fails
```

#### Response
The package was originally called `partial`, but at the time of its original submission this conflicted with a CRAN package of the same name (but with mixed lowercase/uppercase letetrs). At the time I decided to change the name of the package to `pdp`. I've personally never liked the idea of the main function name to be the same as the package name. However, I did add a help file for the page describing the package, main functions, etc. So, `?pdp` no longer fails.


#### Comment
`partial` should return the same value regardless of whether or not the `plot` argument is used?

#### Response
I dont think so and this seems to be the same behavior for the PDP functions in `randomForest` and `gbm`. However, I did add the partial dependence data as an attribute to the returned `"trellis"` object (i.e., plot) so that the user can extract the data easily from that if necessary (e.g., if they do not like the plot and don't want to re-run partial). For example,
```{r}
library(pdp)
data(trees)
mod <- lm(Volume ~ ., data = trees)
pd.Girth <- partial(mod, pred.var = "Girth")  # data only
pdp.Girth <- partial(mod, pred.var = "Girth", plot = TRUE)  # plot
identical(pd.Girth, attr(pdp.Girth, "partial.data"))  # should be identical
```
Also the `lattice` function `trellis.last.object` is now exported when `pdp` is loaded. This will be useful when the user does not store the resulting plot in the call to `partial` but needs to retrieve the outout data to avoid re-running `partial` when computation time is a concern. For example,
```{r}
library(pdp)
data(trees)
mod <- lm(Volume ~ ., data = trees)
partial(mod, pred.var = "Girth", plot = TRUE)
pdp.Girth <- lattice::trellis.last.object()
pd.Girth <- attr(pdp.Girth, "partial.data")
head(pd.Girth)
```


#### Comment
A call to say `par(mfrow = c(2, 2))` before calling `plotPartial` is ignored by `plotPartial`.  This is a pity because it would allow multiple plots to be put on one page like this:
```{r, eval=FALSE}
par(mfrow=c(2,2))
partial(ozone.rf, pred.var = "Temp", plot = TRUE)
partial(ozone.rf, pred.var = "Wind", plot = TRUE)
```

#### Response
The command `par(mfrow = c(2, 2))` does not work with `"trellice"` objects, such as those produced by `lattice` which `partial` relies on for producing its plots. Other methods are available. For example, using the `gridExtra` package:
```{r, eval=TRUE}
library(randomForest)
data(airquality)
ozone.rf <- randomForest(Ozone ~ ., data=airquality, na.action=na.omit)
library(pdp)
pdp1 <- partial(ozone.rf, pred.var = "Temp", plot = TRUE)
pdp2 <- partial(ozone.rf, pred.var = "Wind", plot = TRUE)
gridExtra::grid.arrange(pdp1, pdp2, ncol = 2)
```
However, for convenience, I have included a `multiplot` function that is just a simple wrapper for `gridExtra::grid.arrange` and should satisfy in most cases. For example,
```{r, eval=FALSE}
multiplot(pdp1, pdp2, ncol = 2)
?multiplot
```


#### Comment
It would be nice if the functions automatically plotted all the (important) variables in a grid of plots, without forcing the user to explicitly specify them.

#### Response 
I agree, this would be a nice feature, but the problem I see is that not all models emit a "variable importance". And those that do often have many different ways. For example, random forest offeres two types, which can then be scaled, etc. At this point, I think it is simpler to have the user select which variables they would like to see plotted. But perhaps in the near future. The best way I can see implementing this feature is to have the option when the first argument to `partial` is a `"train"` object (i.e., a model fitted using the `caret` package). `caret` has a generic `varImp` function that applies to a lot of model classes. Perhaps in the near future, a new argument to `partial`, say `top` can be added. So, something like
```{r, eval=FALSE}
library(caret)
library(pdp)
model <- train(x, y, method = "xgbTree", ...)
partial(model, pred.var = 5, plot = TRUE)  # integer indicating using top 5
```
I added this as a feature request on the GitHub page: https://github.com/bgreenwell/pdp/issues/19.


#### Comment
It would be nice if the functions automatically got the data from the model used to build the model in more cases without forcing the user to explicitly specify the data.  Since XGBoost seems now quite popular, perhaps the authors of that package could be persuaded to make the original model data available for functions like partial (currently XGBoost uses a custom object `xgb.DMatrix` which is currently write-only -- one can't access the data stored in `xgb.DMatrix`).

#### Response
This is also true for the fitting functions in other package (e.g., `kernlab::ksvm`). As time goes on, I will try to increase coverage to make it easier on the user. For example, `partial` now works with `caret` which always stores the taining data in a component called `trainingData`. I suspect that package maintainers, especially those for `xgboost`, would be hesitent in storing a copy of the training data as the package is often used for modeling large data sets which they do not


#### Comment
Consider adding a `slowtests` directory (below `pdp/inst/` or elsewhere) that has tests for all the models supported by the package (Table 1 in the paper) to easily check back compatibility when packages change.  (For justification for such tests see for example my
comments on `gbm` back compatibility above.)  These tests will probably be quite slow, but that won't be an issue because they won't be invoked by CRAN check; the slow tests would be just for the maintainer of the `pdp` package to run manually.

#### Response
This is a good suggestion and is currently being put together.


## Reviewer 2


#### Comment 
The Introduction immediately introduces the PDP. You must first motivate why it is important. In a linear model, they are not important. In a linear model with simple interactions, likewise. They first become important if you have non-parametric macine- optimizing techniques. Further, they are not the only idea extant when trying to explain a predictor's impact on the response. This paper would benefit if you can give a bit more of a lit review here.

### Important Clarifications Required:

#### Comment
Top of p2. The `ICEbox` package allows for general construction and visualization of PDP's. However, it is limited as you only get one dimensional representations. The selling point of your package should focus on the flexibility of graphics and the illustration of non- extrapoloation zones.

#### Comment
All `pdp` figures throughout the paper: Can you make explicit in the caption what code produces the left and right subfigures? I would use the subfigure package in latex and then put a comment in the R code e.g. # Fig 3b.

### Edits:

#### Comment
p1 abstract: strict assumptions imposed by traditional statistical models

#### Comment
p1 pairs should be using curly braces of angle braces, not square braces as this is easily confused with closed intervals.

#### Response
Fixed. Switched to curly braces.

#### Comment
p2 unless the editor disagrees, there is no reason to add "install.packages("pdp")" in the text of the paper as it is assumed a user knows how to install a package.

#### Comment
p3 "Error: The training..." should be wrapped.

#### Response
Fixed.

#### Comment
Fig 6: the sidebar should be labeled "ozone". Also, would it be terrible to label all axes even though it is redundant?


#### Comment
Fig 7: as beautiful as this is, you should label the sidebar as "logit" or "centered logit" instead of "y".
#### Response
Fixed. Color key labeled "Average logit".

### Suggestions for the software

#### Comment
I understand that you like the feature of having a one-shot function partial to both generate and plot the PDP. I realize that the default is `FALS`E. However, I still think it's a disservice to the user as constructing PDP's is computationally intense and if they get the plot wrong or it's not to their liking, they will have to regenerate the whole thing again. So, it is my opinion that you should take it out and force two steps: generation and illustration.

#### Comment
The package could be more powerful if you allowed a predict function as a parameter. For instance, you cannot currently use ranfom forests to illustrate classification probabilities.

#### Comment
p7 I believe there are packages allowing for parallelization in Windows. Can you switch the example so this works on all platforms?
